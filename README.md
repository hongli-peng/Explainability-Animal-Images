# Explainability-Animal-Images
In this project, we will consider several methods for explaining the outputs of predictive models. We will focus on attribution methods, which try to weight the relitive importance of inputs with respect to making a prediction. It is important to note there are many methods for considering the interactions between variables. This assignment will not consider those methods, because they get complicated quickly. Instead, we will focus on attribution methods such as `LIME`, `Shapley Values`, and `SmoothGrad`.

# Datasets:
The project will make use of two distinct datasets:

- `Pima Indians Diabetes Database`: This tabular database has several health diagnostic measures such as blood pressure, and the goal is to predict if a patient has diabetes.
- `ANIMAL-10N Image Classification Dataset`: The ANIMAL-10N dataset consists of ten classes of animals, comprising 50,000 training images and 5,000 testing images. The task is to develop a model capable of accurately classifying the animal depicted in a given image.

